{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keMKeHoVmnR1"
   },
   "source": [
    "# Train and evaluate the model on NNH6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xM-VeXKduSt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import random\n",
    "from time import sleep\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1565695084368,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "vN8QLpgkAnHG",
    "outputId": "e39d2061-02e9-483a-c8cc-467f83c836f0"
   },
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "from evaluation import Evaluator\n",
    "from datasets import NN6H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1565642894962,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "8GT8Pb7DKUvY",
    "outputId": "38a16172-6d2f-4833-da99-14c2ca81b0de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.17303466796875"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0).total_memory/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68RcyZ5_F9xH"
   },
   "outputs": [],
   "source": [
    "loss_bce = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "def lossPY(alphay, weighty, y, z, w, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  \n",
    "  if cov == None:\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, Kw, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + w.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  \n",
    "  f = weighty + lz + lw + ls\n",
    "\n",
    "  return torch.sum((y - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def QZ(alphaq, weightq, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "  \n",
    "def lossQZ(alphaq, weightq, z, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "  \n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  f = weightq + ly + lx + lw + ls\n",
    "  \n",
    "  return torch.sum((z - f.reshape(-1,1))**2) - 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPX(alphax, weightx, x, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return torch.sum((x - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def lossPW(alphaw, weightw, w, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "    \n",
    "  lz = torch.sum(Kz*alphaw[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphaw[:,1],dim=1)\n",
    "  \n",
    "  f = weightw + lz + ls\n",
    "\n",
    "  return loss_bce(f.reshape(-1,1),w) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPS(weights, s):\n",
    "  return torch.sum((s - weights)**2)\n",
    "\n",
    "\n",
    "def lossPZ(alphaz, weightz, z):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  Kz[np.triu_indices(len(z))] = 0\n",
    "  alphaz_ = torch.cat((alphaz[:,0], torch.tensor([1.0, 1.0])))\n",
    "  f = weightz + torch.sum(Kz*alphaz_,dim=1)[:-1]\n",
    "  return torch.sum((z[0] - weightz)**2) + torch.sum((z[1:] - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def trainModel(x, y, w, s, cov=None, n_iter=20000):\n",
    "  loss_lst = []\n",
    "  prog = trange(n_iter, desc='', leave=True)\n",
    "  for t in prog:\n",
    "      mean_z = QZ(alphaq, weightq, y, x, w, s, cov)\n",
    "      z = mean_z + torch.randn(mean_z.shape)\n",
    "\n",
    "      loss = lossPY(alphay, weighty, y, z, w, s, cov) + lossPX(alphax, weightx, x, z, s, cov) +\\\n",
    "              lossPW(alphaw, weightw, w, z, s, cov) + lossPS(weights, s) +\\\n",
    "                lossPZ(alphaz, weightz, z) - lossQZ(alphaq, weightq, z, y, x, w, s, cov)\n",
    "\n",
    "      if t%50 == 0:\n",
    "        prog.set_postfix_str(\"Iter {}:, Loss: {}\".format(t,loss.item()))\n",
    "        prog.refresh()\n",
    "        \n",
    "      loss_lst.append(loss.item())\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer.step()\n",
    "  return np.asarray(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bne9WNZKR0a"
   },
   "outputs": [],
   "source": [
    "def predZ(alphaq, weightq, y, x, w, s, ynew, xnew, wnew, snew):\n",
    "  Ky = materny(ynew, y).evaluate()\n",
    "  Kx = maternx(xnew, x).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "\n",
    "\n",
    "def evalLogPX(alphax, weightx, x, z, s, xpre, zpre, spre):\n",
    "  Kz = maternz(zpre, z).evaluate()\n",
    "  Ks = materns(spre, s).evaluate()\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return (-0.5*np.log(2*np.pi) - 0.5*(Xpre - f.reshape(-1,1))**2).detach().numpy().flatten()\n",
    "\n",
    "def sampleY(z, w, s, znew, wnew, snew, alphay, weighty, weights_mixture, T, n):\n",
    "  Y_samples = []\n",
    "  \n",
    "  Kz = maternz(znew, z).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  f = weighty + lz + lw + ls\n",
    "  for i in range(n):\n",
    "    noise = torch.from_numpy(np.random.normal(0,1,T)).float()\n",
    "\n",
    "    Y = f + noise\n",
    "    Y_samples.append(Y.detach().numpy())\n",
    "  return np.asarray(Y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3267284,
     "status": "ok",
     "timestamp": 1565646172309,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "jBK2tVSYp5o4",
    "outputId": "1dcad8d9-fa71-4de5-87b6-a71f3b7b45d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:18<00:00, 63.51it/s, Iter 19950:, Loss: 5987.0986328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9326937744646466, 0.18730126388549806, 0.1922929933451066)\n",
      "Test: (1.2121361065472571, 0.1968699551391584, 0.20138206158938338)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:23<00:00, 61.75it/s, Iter 19950:, Loss: 9905.4912109375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8033539512246795, 0.013810728479393575, 0.05325361628039254)\n",
      "Test: (0.5603589142674812, 0.011774168090819437, 0.04637805498280803)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:27<00:00, 61.00it/s, Iter 19950:, Loss: 11169.6474609375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.917090654065954, 0.2553578472900373, 0.2599151031329104)\n",
      "Test: (0.8236599866766205, 0.2542611218261701, 0.2575893777233656)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:26<00:00, 61.21it/s, Iter 19950:, Loss: 7456.40185546875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.843071204422361, 0.38777483932495294, 0.3900992736311806)\n",
      "Test: (0.8068073718667105, 0.385496034545902, 0.388328021663832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:27<00:00, 61.09it/s, Iter 19950:, Loss: 9039.45703125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.045905365129434, 0.04814805023193536, 0.06535677784210754)\n",
      "Test: (1.0149255890477094, 0.04526318542480556, 0.059979447439006836)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:28<00:00, 60.86it/s, Iter 19950:, Loss: 8185.89501953125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9204178380837592, 0.12017716400146483, 0.12799489962555105)\n",
      "Test: (1.74943187211968, 0.11324919692993518, 0.1219634946908945)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:26<00:00, 61.28it/s, Iter 19950:, Loss: 6610.07470703125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0869233140272423, 0.5098820782470703, 0.51181396881594)\n",
      "Test: (1.0950672731022872, 0.5116702175903303, 0.5136621875398184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:26<00:00, 63.05it/s, Iter 19950:, Loss: 10605.0771484375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9661575124183376, 0.08151732452392402, 0.09414467287979737)\n",
      "Test: (1.4574771516261567, 0.07609663970947, 0.08367720031179623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:24<00:00, 61.58it/s, Iter 19950:, Loss: 8054.82861328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8690872801766188, 0.4772967242431658, 0.4793131246714915)\n",
      "Test: (0.8344210017930785, 0.46985639564514337, 0.4720887186424646)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:24<00:00, 61.64it/s, Iter 19950:, Loss: 8059.46923828125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.1793188586816015, 0.31562584643352487, 0.32891374688665787)\n",
      "Test: (1.3832064128196966, 0.3004489994812012, 0.30518668652641484)\n"
     ]
    }
   ],
   "source": [
    "learn_hyper = False\n",
    "\n",
    "dataset = NN6H(replications=10)\n",
    "\n",
    "train_stats = []\n",
    "test_stats = []\n",
    "loss_lst = []\n",
    "for i, (train, valid, test, contfeats, binfeats) in enumerate(dataset.get_train_valid_test()):\n",
    "  W, Y, Y_cf, mu, X, S = train[0][1].reshape(-1), train[0][2].reshape(-1), train[1][0].reshape(-1),\\\n",
    "                          np.concatenate((train[1][1],train[1][2]),axis=1).T, train[0][0][:,0], train[0][0][:,1]\n",
    "  T = len(Y)\n",
    "  x = torch.from_numpy(X.reshape(T,-1)).float() \n",
    "  y = torch.from_numpy(Y.reshape(-1,1)).float()\n",
    "  w = torch.from_numpy(W.reshape(-1,1)).float()\n",
    "  s = torch.from_numpy(S.reshape(T,-1)).float()\n",
    "  \n",
    "  Wte, Yte, Y_cfte, mute, Xte, Ste = test[0][1].reshape(-1), test[0][2].reshape(-1), test[1][0].reshape(-1), \\\n",
    "                                      np.concatenate((test[1][1],test[1][2]), axis=1).T, test[0][0][:,0], test[0][0][:,1]\n",
    "  Tte = len(Yte)\n",
    "  xte = torch.from_numpy(Xte.reshape(Tte,-1)).float() \n",
    "  yte = torch.from_numpy(Yte.reshape(-1,1)).float()\n",
    "  wte = torch.from_numpy(Wte.reshape(-1,1)).float()\n",
    "  ste = torch.from_numpy(Ste.reshape(Tte,-1)).float()\n",
    "  \n",
    "  # Compute kernel matrices\n",
    "  maternx = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternx.initialize(lengthscale=10.0)\n",
    "  materns = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  materns.initialize(lengthscale=10.0)\n",
    "  materny = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  materny.initialize(lengthscale=10.0)\n",
    "  maternz = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternz.initialize(lengthscale=10.0)\n",
    "  maternw = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternw.initialize(lengthscale=10.0)\n",
    "  \n",
    "  Ky = materny(y, y).evaluate()\n",
    "  Kx = maternx(x, x).evaluate()\n",
    "  Kw = maternw(w, w).evaluate()\n",
    "  Ks = materns(s, s).evaluate()\n",
    "  if learn_hyper == False:\n",
    "    cov = (Ky, Kw, Kx, Ks)\n",
    "  else:\n",
    "    cov = None\n",
    "  \n",
    "  # Declare parameters\n",
    "  alphay = torch.rand(len(y), 4, requires_grad=True)\n",
    "  weighty = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaq = torch.rand(len(y), 5, requires_grad=True)\n",
    "  weightq = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphax = torch.rand(len(x), 2, requires_grad=True)\n",
    "  weightx = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaw = torch.rand(len(w), 2, requires_grad=True)\n",
    "  weightw = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  weights = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaz = torch.rand(len(y)-2, 1, requires_grad=True)\n",
    "  weightz = torch.rand(1, requires_grad=True)  \n",
    "  \n",
    "  # Train\n",
    "  params = [alphay, alphaq, alphax, alphaw, alphaz, weighty, weightq, weightx, weightw, weightz, weights]\n",
    "  if learn_hyper == True:\n",
    "    params = params + list(maternx.parameters()) + list(materns.parameters()) + list(maternw.parameters()) \\\n",
    "                    + list(materny.parameters()) + list(maternz.parameters())\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "  loss_train = trainModel(x, y, w, s, cov=cov, n_iter=20000)\n",
    "  loss_lst.append(loss_train)\n",
    "\n",
    "  # Sample Ypred\n",
    "  z_samples = predZ(alphaq, weightq, y, x, w, s,\n",
    "                   torch.cat((y,yte),dim=0), torch.cat((x,xte),dim=0), torch.cat((w,wte),dim=0), torch.cat((s,ste),dim=0)).transpose(0,1)\n",
    "  weights_mixture = 1.0\n",
    "\n",
    "  Y_samples1 = sampleY(z_samples[0,:T].reshape(-1,1), torch.ones((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.ones((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Y_samples2 = sampleY(z_samples[0,:T].reshape(-1,1), torch.zeros((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.zeros((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Ypred1 = np.mean(Y_samples1,axis=0)\n",
    "  Ypred0 = np.mean(Y_samples2,axis=0)\n",
    "  \n",
    "  # Evaluate\n",
    "  evaluator_train = Evaluator(y=Y, t=W, y_cf=Y_cf, mu0=mu[0,:], mu1=mu[1,:])\n",
    "  stat = evaluator_train.calc_stats(Ypred1[:T],Ypred0[:T])\n",
    "  train_stats.append(stat)\n",
    "  print('Train:', stat)\n",
    "\n",
    "  evaluator_test = Evaluator(y=Yte, t=Wte, y_cf=Y_cfte, mu0=mute[0,:], mu1=mute[1,:])\n",
    "  stat = evaluator_test.calc_stats(Ypred1[T:],Ypred0[T:])\n",
    "  test_stats.append(stat)\n",
    "  print('Test:', stat)\n",
    "  \n",
    "  sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1565695166086,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "j2-IwGrZcnM5",
    "outputId": "231f9f0e-0eaf-42f2-9120-215468694e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.95640198, 0.23968919, 0.25030982]),\n",
       " array([0.11417695, 0.05640551, 0.05424444]))"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_stats,axis=0), np.std(test_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1565695155515,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "gSDi9g76hfUe",
    "outputId": "710f26f3-495b-4729-d21b-2c27a24cbb62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.09374917, 0.23649859, 0.24502353]),\n",
       " array([0.11417695, 0.05640551, 0.05424444]))"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_stats,axis=0), np.std(test_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LMCM - NN6H.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
