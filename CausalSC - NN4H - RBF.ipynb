{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keMKeHoVmnR1"
   },
   "source": [
    "# Train and evaluate the model on NN4H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xM-VeXKduSt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import random\n",
    "from time import sleep\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2992,
     "status": "ok",
     "timestamp": 1590853613928,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "vN8QLpgkAnHG",
    "outputId": "55212666-45f8-4564-8fde-d7c35253dba4"
   },
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "from evaluation import Evaluator\n",
    "from datasets import NN4H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1187,
     "status": "ok",
     "timestamp": 1590853615168,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "8GT8Pb7DKUvY",
    "outputId": "3f7f0eaa-20cc-48d3-d589-6416a1c83311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.8992919921875"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0).total_memory/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68RcyZ5_F9xH"
   },
   "outputs": [],
   "source": [
    "loss_bce = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "def lossPY(alphay, weighty, y, z, w, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  \n",
    "  if cov == None:\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, Kw, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + w.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  \n",
    "  f = weighty + lz + lw + ls\n",
    "\n",
    "  return torch.sum((y - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def QZ(alphaq, weightq, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "  \n",
    "def lossQZ(alphaq, weightq, z, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "  \n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  f = weightq + ly + lx + lw + ls\n",
    "  \n",
    "  return torch.sum((z - f.reshape(-1,1))**2) - 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPX(alphax, weightx, x, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return torch.sum((x - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def lossPW(alphaw, weightw, w, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "    \n",
    "  lz = torch.sum(Kz*alphaw[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphaw[:,1],dim=1)\n",
    "  \n",
    "  f = weightw + lz + ls\n",
    "\n",
    "  return loss_bce(f.reshape(-1,1),w) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPS(weights, s):\n",
    "  return torch.sum((s - weights)**2)\n",
    "\n",
    "\n",
    "def lossPZ(alphaz, weightz, z):\n",
    "  Kz = maternz(z, z).evaluate()*lower_ones\n",
    "  alphaz_ = torch.cat((alphaz[:,0], torch.tensor([1.0, 1.0])))\n",
    "  f = weightz + torch.sum(Kz*alphaz_,dim=1)[:-1]\n",
    "  return torch.sum((z[0] - weightz)**2) + torch.sum((z[1:] - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def trainModel(x, y, w, s, cov=None, n_iter=20000):\n",
    "  loss_lst = []\n",
    "  prog = trange(n_iter, desc='', leave=True)\n",
    "  for t in prog:\n",
    "      mean_z = QZ(alphaq, weightq, y, x, w, s, cov)\n",
    "      z = mean_z + torch.randn(mean_z.shape)\n",
    "\n",
    "      loss = lossPY(alphay, weighty, y, z, w, s, cov) + lossPX(alphax, weightx, x, z, s, cov) +\\\n",
    "              lossPW(alphaw, weightw, w, z, s, cov) + lossPS(weights, s) +\\\n",
    "                lossPZ(alphaz, weightz, z) - lossQZ(alphaq, weightq, z, y, x, w, s, cov)\n",
    "\n",
    "      if t%50 == 0:\n",
    "        prog.set_postfix_str(\"Iter {}:, Loss: {}\".format(t,loss.item()))\n",
    "        prog.refresh()\n",
    "        \n",
    "      loss_lst.append(loss.item())\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer.step()\n",
    "  return np.asarray(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bne9WNZKR0a"
   },
   "outputs": [],
   "source": [
    "def predZ(alphaq, weightq, y, x, w, s, ynew, xnew, wnew, snew):\n",
    "  Ky = materny(ynew, y).evaluate()\n",
    "  Kx = maternx(xnew, x).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "\n",
    "\n",
    "def evalLogPX(alphax, weightx, x, z, s, xpre, zpre, spre):\n",
    "  Kz = maternz(zpre, z).evaluate()\n",
    "  Ks = materns(spre, s).evaluate()\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return (-0.5*np.log(2*np.pi) - 0.5*(Xpre - f.reshape(-1,1))**2).detach().numpy().flatten()\n",
    "\n",
    "def sampleY(z, w, s, znew, wnew, snew, alphay, weighty, weights_mixture, T, n):\n",
    "  Y_samples = []\n",
    "  \n",
    "  Kz = maternz(znew, z).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  f = weighty + lz + lw + ls\n",
    "  for i in range(n):\n",
    "    noise = torch.from_numpy(np.random.normal(0,1,T)).float()\n",
    "\n",
    "    Y = f + noise\n",
    "    Y_samples.append(Y.detach().numpy())\n",
    "  return np.asarray(Y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1835286,
     "status": "ok",
     "timestamp": 1590855533639,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "jBK2tVSYp5o4",
    "outputId": "a2ab7a10-3cfc-4348-b224-be5ecfdccf0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:08<00:00, 106.23it/s, Iter 19950:, Loss: 5984.4853515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0470800399628617, 0.10789595611572267, 0.11634540805478527)\n",
      "Test: (1.2859209989352334, 0.11746893890380683, 0.12488514337412471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:05<00:00, 107.81it/s, Iter 19950:, Loss: 9914.228515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8737095459210746, 0.16566667406655267, 0.1734661080293692)\n",
      "Test: (0.5709836664046991, 0.16363678939819248, 0.16967411789148346)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:04<00:00, 108.28it/s, Iter 19950:, Loss: 11184.146484375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.1311618214624748, 0.1224247074890128, 0.13166714420649395)\n",
      "Test: (1.0116367820745888, 0.12133418090820136, 0.1281623263295995)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:01<00:00, 110.05it/s, Iter 19950:, Loss: 7459.76025390625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9675927478808345, 0.5405239009094256, 0.5421937934469528)\n",
      "Test: (0.6176014436114533, 0.5382379435730016, 0.5402696525070274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:03<00:00, 109.20it/s, Iter 19950:, Loss: 9066.5498046875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.1673833155985047, 0.04908265106201348, 0.06605027150711114)\n",
      "Test: (1.249498005446018, 0.04619301788330166, 0.06068615584282313)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:02<00:00, 109.53it/s, Iter 19950:, Loss: 8199.138671875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0360925501926355, 0.19912634857177736, 0.20394010657272527)\n",
      "Test: (1.2695356347375086, 0.2060557461547825, 0.2109712134247456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:57<00:00, 112.44it/s, Iter 19950:, Loss: 6623.99560546875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.3388149918095251, 0.7831336117553711, 0.7843923981846673)\n",
      "Test: (1.0056408587394314, 0.7849169827270508, 0.7862171930885274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:01<00:00, 110.29it/s, Iter 19950:, Loss: 10597.43359375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0265954401564272, 0.15534792907714667, 0.16232943518129192)\n",
      "Test: (1.473331407927453, 0.1499320126342747, 0.15391723777615296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:00<00:00, 110.82it/s, Iter 19950:, Loss: 8051.5068359375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8891896850456132, 0.27850712768554864, 0.28194917889933524)\n",
      "Test: (0.9679666872026551, 0.27106226913452325, 0.2749126015940061)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:57<00:00, 112.55it/s, Iter 19950:, Loss: 8047.927734375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.324777784004254, 0.504612147855644, 0.5130282747911616)\n",
      "Test: (1.5289416605022386, 0.48943673141479493, 0.49235790359357295)\n"
     ]
    }
   ],
   "source": [
    "learn_hyper = False\n",
    "\n",
    "dataset = NN4H(replications=10)\n",
    "\n",
    "train_stats = []\n",
    "test_stats = []\n",
    "loss_lst = []\n",
    "for i, (train, valid, test, contfeats, binfeats) in enumerate(dataset.get_train_valid_test()):\n",
    "  W, Y, Y_cf, mu, X, S = train[0][1].reshape(-1), train[0][2].reshape(-1), train[1][0].reshape(-1),\\\n",
    "                          np.concatenate((train[1][1],train[1][2]),axis=1).T, train[0][0][:,0], train[0][0][:,1]\n",
    "  T = len(Y)\n",
    "  x = torch.from_numpy(X.reshape(T,-1)).float() \n",
    "  y = torch.from_numpy(Y.reshape(-1,1)).float()\n",
    "  w = torch.from_numpy(W.reshape(-1,1)).float()\n",
    "  s = torch.from_numpy(S.reshape(T,-1)).float()\n",
    "  \n",
    "  Wte, Yte, Y_cfte, mute, Xte, Ste = test[0][1].reshape(-1), test[0][2].reshape(-1), test[1][0].reshape(-1), \\\n",
    "                                      np.concatenate((test[1][1],test[1][2]), axis=1).T, test[0][0][:,0], test[0][0][:,1]\n",
    "  Tte = len(Yte)\n",
    "  xte = torch.from_numpy(Xte.reshape(Tte,-1)).float() \n",
    "  yte = torch.from_numpy(Yte.reshape(-1,1)).float()\n",
    "  wte = torch.from_numpy(Wte.reshape(-1,1)).float()\n",
    "  ste = torch.from_numpy(Ste.reshape(Tte,-1)).float()\n",
    "\n",
    "  lower_ones = torch.ones(len(y), len(y))\n",
    "  lower_ones[np.triu_indices(len(y))] = 0\n",
    "  \n",
    "  # Compute kernel matrices\n",
    "  maternx = gpytorch.kernels.RBFKernel()\n",
    "  maternx.initialize(lengthscale=10.0)\n",
    "  materns = gpytorch.kernels.RBFKernel()\n",
    "  materns.initialize(lengthscale=10.0)\n",
    "  materny = gpytorch.kernels.RBFKernel()\n",
    "  materny.initialize(lengthscale=10.0)\n",
    "  maternz = gpytorch.kernels.RBFKernel()\n",
    "  maternz.initialize(lengthscale=10.0)\n",
    "  maternw = gpytorch.kernels.RBFKernel()\n",
    "  maternw.initialize(lengthscale=10.0)\n",
    "  \n",
    "  Ky = materny(y, y).evaluate()\n",
    "  Kx = maternx(x, x).evaluate()\n",
    "  Kw = maternw(w, w).evaluate()\n",
    "  Ks = materns(s, s).evaluate()\n",
    "  if learn_hyper == False:\n",
    "    cov = (Ky, Kw, Kx, Ks)\n",
    "  else:\n",
    "    cov = None\n",
    "  \n",
    "  # Declare parameters\n",
    "  alphay = torch.rand(len(y), 4, requires_grad=True)\n",
    "  weighty = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaq = torch.rand(len(y), 5, requires_grad=True)\n",
    "  weightq = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphax = torch.rand(len(x), 2, requires_grad=True)\n",
    "  weightx = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaw = torch.rand(len(w), 2, requires_grad=True)\n",
    "  weightw = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  weights = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaz = torch.rand(len(y)-2, 1, requires_grad=True)\n",
    "  weightz = torch.rand(1, requires_grad=True)  \n",
    "  \n",
    "  # Train\n",
    "  params = [alphay, alphaq, alphax, alphaw, alphaz, weighty, weightq, weightx, weightw, weightz, weights]\n",
    "  if learn_hyper == True:\n",
    "    params = params + list(maternx.parameters()) + list(materns.parameters()) + list(maternw.parameters()) \\\n",
    "                    + list(materny.parameters()) + list(maternz.parameters())\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "  loss_train = trainModel(x, y, w, s, cov=cov, n_iter=20000)\n",
    "  loss_lst.append(loss_train)\n",
    "\n",
    "  # Sample Ypred\n",
    "  z_samples = predZ(alphaq, weightq, y, x, w, s,\n",
    "                   torch.cat((y,yte),dim=0), torch.cat((x,xte),dim=0), torch.cat((w,wte),dim=0), torch.cat((s,ste),dim=0)).transpose(0,1)\n",
    "  weights_mixture = 1.0\n",
    "\n",
    "  Y_samples1 = sampleY(z_samples[0,:T].reshape(-1,1), torch.ones((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.ones((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Y_samples2 = sampleY(z_samples[0,:T].reshape(-1,1), torch.zeros((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.zeros((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Ypred1 = np.mean(Y_samples1,axis=0)\n",
    "  Ypred0 = np.mean(Y_samples2,axis=0)\n",
    "  \n",
    "  # Evaluate\n",
    "  evaluator_train = Evaluator(y=Y, t=W, y_cf=Y_cf, mu0=mu[0,:], mu1=mu[1,:])\n",
    "  stat = evaluator_train.calc_stats(Ypred1[:T],Ypred0[:T])\n",
    "  train_stats.append(stat)\n",
    "  print('Train:', stat)\n",
    "\n",
    "  evaluator_test = Evaluator(y=Yte, t=Wte, y_cf=Y_cfte, mu0=mute[0,:], mu1=mute[1,:])\n",
    "  stat = evaluator_test.calc_stats(Ypred1[T:],Ypred0[T:])\n",
    "  test_stats.append(stat)\n",
    "  print('Test:', stat)\n",
    "  \n",
    "  sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1427,
     "status": "ok",
     "timestamp": 1590855536285,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "j2-IwGrZcnM5",
    "outputId": "3aade28f-3947-418d-bf78-bafa377c84d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.08023979, 0.29063211, 0.29753621]),\n",
       " array([0.15317229, 0.22655285, 0.22359091]))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_stats,axis=0), np.std(train_stats,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1590855537407,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "gSDi9g76hfUe",
    "outputId": "e575530c-9020-4604-d1ef-e70939a1dc44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.09810571, 0.28882746, 0.29420535]),\n",
       " array([0.30914417, 0.22516108, 0.22251909]))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_stats,axis=0), np.std(test_stats,axis=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LMCM - RT - NN4H - RBF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
