{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keMKeHoVmnR1"
   },
   "source": [
    "# Train and evaluate the model on NN2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xM-VeXKduSt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import random\n",
    "from time import sleep\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12680,
     "status": "ok",
     "timestamp": 1565707748581,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "vN8QLpgkAnHG",
    "outputId": "135d03e7-6207-4ef4-e5c9-b9e66d3cad30"
   },
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "from evaluation import Evaluator\n",
    "from datasets import NN2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1588,
     "status": "ok",
     "timestamp": 1565649884094,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "8GT8Pb7DKUvY",
    "outputId": "598db18a-3a90-4d8f-fc7f-90e1044d3fa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.17303466796875"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0).total_memory/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68RcyZ5_F9xH"
   },
   "outputs": [],
   "source": [
    "loss_bce = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "def lossPY(alphay, weighty, y, z, w, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  \n",
    "  if cov == None:\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, Kw, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + w.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  \n",
    "  f = weighty + lz + lw + ls\n",
    "\n",
    "  return torch.sum((y - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def QZ(alphaq, weightq, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "  \n",
    "def lossQZ(alphaq, weightq, z, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "  \n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  f = weightq + ly + lx + lw + ls\n",
    "  \n",
    "  return torch.sum((z - f.reshape(-1,1))**2) - 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPX(alphax, weightx, x, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return torch.sum((x - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def lossPW(alphaw, weightw, w, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "    \n",
    "  lz = torch.sum(Kz*alphaw[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphaw[:,1],dim=1)\n",
    "  \n",
    "  f = weightw + lz + ls\n",
    "\n",
    "  return loss_bce(f.reshape(-1,1),w) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPS(weights, s):\n",
    "  return torch.sum((s - weights)**2)\n",
    "\n",
    "\n",
    "def lossPZ(alphaz, weightz, z):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  Kz[np.triu_indices(len(z))] = 0\n",
    "  alphaz_ = torch.cat((alphaz[:,0], torch.tensor([1.0, 1.0])))\n",
    "  f = weightz + torch.sum(Kz*alphaz_,dim=1)[:-1]\n",
    "  return torch.sum((z[0] - weightz)**2) + torch.sum((z[1:] - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def trainModel(x, y, w, s, cov=None, n_iter=20000):\n",
    "  loss_lst = []\n",
    "  prog = trange(n_iter, desc='', leave=True)\n",
    "  for t in prog:\n",
    "      mean_z = QZ(alphaq, weightq, y, x, w, s, cov)\n",
    "      z = mean_z + torch.randn(mean_z.shape)\n",
    "\n",
    "      loss = lossPY(alphay, weighty, y, z, w, s, cov) + lossPX(alphax, weightx, x, z, s, cov) +\\\n",
    "              lossPW(alphaw, weightw, w, z, s, cov) + lossPS(weights, s) +\\\n",
    "                lossPZ(alphaz, weightz, z) - lossQZ(alphaq, weightq, z, y, x, w, s, cov)\n",
    "\n",
    "      if t%50 == 0:\n",
    "        prog.set_postfix_str(\"Iter {}:, Loss: {}\".format(t,loss.item()))\n",
    "        prog.refresh()\n",
    "        \n",
    "      loss_lst.append(loss.item())\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer.step()\n",
    "  return np.asarray(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bne9WNZKR0a"
   },
   "outputs": [],
   "source": [
    "def predZ(alphaq, weightq, y, x, w, s, ynew, xnew, wnew, snew):\n",
    "  Ky = materny(ynew, y).evaluate()\n",
    "  Kx = maternx(xnew, x).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "\n",
    "\n",
    "def evalLogPX(alphax, weightx, x, z, s, xpre, zpre, spre):\n",
    "  Kz = maternz(zpre, z).evaluate()\n",
    "  Ks = materns(spre, s).evaluate()\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return (-0.5*np.log(2*np.pi) - 0.5*(Xpre - f.reshape(-1,1))**2).detach().numpy().flatten()\n",
    "\n",
    "def sampleY(z, w, s, znew, wnew, snew, alphay, weighty, weights_mixture, T, n):\n",
    "  Y_samples = []\n",
    "  \n",
    "  Kz = maternz(znew, z).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  f = weighty + lz + lw + ls\n",
    "  for i in range(n):\n",
    "    noise = torch.from_numpy(np.random.normal(0,1,T)).float()\n",
    "\n",
    "    Y = f + noise\n",
    "    Y_samples.append(Y.detach().numpy())\n",
    "  return np.asarray(Y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3204540,
     "status": "ok",
     "timestamp": 1565653095682,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "jBK2tVSYp5o4",
    "outputId": "beae8e43-5bb4-4643-ca0c-08050499d6f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:18<00:00, 62.78it/s, Iter 19950:, Loss: 6102.3046875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0120021333619773, 0.13175798797607463, 0.13876317480157624)\n",
      "Test: (1.4995844366235322, 0.14132906341552776, 0.14755045952662693)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:17<00:00, 62.93it/s, Iter 19950:, Loss: 10024.70703125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.818943821782084, 0.037455375425007986, 0.07103551859386442)\n",
      "Test: (0.5915029097024215, 0.04061101531982292, 0.06051080221941223)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:18<00:00, 62.81it/s, Iter 19950:, Loss: 11307.1572265625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9467575895469738, 0.27645756149292033, 0.2806721694363899)\n",
      "Test: (0.8183293605886803, 0.27536035919189583, 0.2784360123947003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:18<00:00, 62.84it/s, Iter 19950:, Loss: 7571.55859375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9024633908128874, 0.5229127273559566, 0.5246388718353389)\n",
      "Test: (1.0063205186101523, 0.5206372604370113, 0.522737204170985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:18<00:00, 62.71it/s, Iter 19950:, Loss: 9162.57421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.1168169124275305, 0.12385009384155232, 0.13150105035890203)\n",
      "Test: (1.0965215579004108, 0.12096570587158162, 0.12720711299965803)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:19<00:00, 62.63it/s, Iter 19950:, Loss: 8286.689453125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.959573794990229, 0.0770037307739253, 0.08871006366103346)\n",
      "Test: (2.232222874008034, 0.0839302673339839, 0.09536125721859177)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:21<00:00, 62.12it/s, Iter 19950:, Loss: 6712.98046875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.051341650940865, 0.47828508758544963, 0.48034350785788577)\n",
      "Test: (1.0326388437460812, 0.4800655975341792, 0.4821878797389689)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:19<00:00, 62.65it/s, Iter 19950:, Loss: 10733.076171875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0439729108570495, 0.17164112472534132, 0.1779851524070484)\n",
      "Test: (1.6538740263822056, 0.16622568511962932, 0.16982884981071564)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:19<00:00, 62.51it/s, Iter 19950:, Loss: 8162.9306640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0399272067873815, 0.6177098617553725, 0.619268730364379)\n",
      "Test: (0.9298655994820516, 0.6102559432983394, 0.6119763775367342)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:20<00:00, 62.44it/s, Iter 19950:, Loss: 8170.25732421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.2657289835773742, 0.575387408402074, 0.587722980690776)\n",
      "Test: (1.434968829880022, 0.5575325622558607, 0.5601007405860933)\n"
     ]
    }
   ],
   "source": [
    "learn_hyper = False\n",
    "\n",
    "dataset = NN2H(replications=10)\n",
    "\n",
    "train_stats = []\n",
    "test_stats = []\n",
    "loss_lst = []\n",
    "for i, (train, valid, test, contfeats, binfeats) in enumerate(dataset.get_train_valid_test()):\n",
    "  W, Y, Y_cf, mu, X, S = train[0][1].reshape(-1), train[0][2].reshape(-1), train[1][0].reshape(-1),\\\n",
    "                          np.concatenate((train[1][1],train[1][2]),axis=1).T, train[0][0][:,0], train[0][0][:,1]\n",
    "  T = len(Y)\n",
    "  x = torch.from_numpy(X.reshape(T,-1)).float() \n",
    "  y = torch.from_numpy(Y.reshape(-1,1)).float()\n",
    "  w = torch.from_numpy(W.reshape(-1,1)).float()\n",
    "  s = torch.from_numpy(S.reshape(T,-1)).float()\n",
    "  \n",
    "  Wte, Yte, Y_cfte, mute, Xte, Ste = test[0][1].reshape(-1), test[0][2].reshape(-1), test[1][0].reshape(-1), \\\n",
    "                                      np.concatenate((test[1][1],test[1][2]), axis=1).T, test[0][0][:,0], test[0][0][:,1]\n",
    "  Tte = len(Yte)\n",
    "  xte = torch.from_numpy(Xte.reshape(Tte,-1)).float() \n",
    "  yte = torch.from_numpy(Yte.reshape(-1,1)).float()\n",
    "  wte = torch.from_numpy(Wte.reshape(-1,1)).float()\n",
    "  ste = torch.from_numpy(Ste.reshape(Tte,-1)).float()\n",
    "  \n",
    "  # Compute kernel matrices\n",
    "  maternx = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternx.initialize(lengthscale=10.0)\n",
    "  materns = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  materns.initialize(lengthscale=10.0)\n",
    "  materny = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  materny.initialize(lengthscale=10.0)\n",
    "  maternz = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternz.initialize(lengthscale=10.0)\n",
    "  maternw = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternw.initialize(lengthscale=10.0)\n",
    "  \n",
    "  Ky = materny(y, y).evaluate()\n",
    "  Kx = maternx(x, x).evaluate()\n",
    "  Kw = maternw(w, w).evaluate()\n",
    "  Ks = materns(s, s).evaluate()\n",
    "  if learn_hyper == False:\n",
    "    cov = (Ky, Kw, Kx, Ks)\n",
    "  else:\n",
    "    cov = None\n",
    "  \n",
    "  # Declare parameters\n",
    "  alphay = torch.rand(len(y), 4, requires_grad=True)\n",
    "  weighty = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaq = torch.rand(len(y), 5, requires_grad=True)\n",
    "  weightq = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphax = torch.rand(len(x), 2, requires_grad=True)\n",
    "  weightx = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaw = torch.rand(len(w), 2, requires_grad=True)\n",
    "  weightw = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  weights = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaz = torch.rand(len(y)-2, 1, requires_grad=True)\n",
    "  weightz = torch.rand(1, requires_grad=True)  \n",
    "  \n",
    "  # Train\n",
    "  params = [alphay, alphaq, alphax, alphaw, alphaz, weighty, weightq, weightx, weightw, weightz, weights]\n",
    "  if learn_hyper == True:\n",
    "    params = params + list(maternx.parameters()) + list(materns.parameters()) + list(maternw.parameters()) \\\n",
    "                    + list(materny.parameters()) + list(maternz.parameters())\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "  loss_train = trainModel(x, y, w, s, cov=cov, n_iter=20000)\n",
    "  loss_lst.append(loss_train)\n",
    "\n",
    "  # Sample Ypred\n",
    "  z_samples = predZ(alphaq, weightq, y, x, w, s,\n",
    "                   torch.cat((y,yte),dim=0), torch.cat((x,xte),dim=0), torch.cat((w,wte),dim=0), torch.cat((s,ste),dim=0)).transpose(0,1)\n",
    "  weights_mixture = 1.0\n",
    "\n",
    "  Y_samples1 = sampleY(z_samples[0,:T].reshape(-1,1), torch.ones((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.ones((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Y_samples2 = sampleY(z_samples[0,:T].reshape(-1,1), torch.zeros((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.zeros((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Ypred1 = np.mean(Y_samples1,axis=0)\n",
    "  Ypred0 = np.mean(Y_samples2,axis=0)\n",
    "  \n",
    "  # Evaluate\n",
    "  evaluator_train = Evaluator(y=Y, t=W, y_cf=Y_cf, mu0=mu[0,:], mu1=mu[1,:])\n",
    "  stat = evaluator_train.calc_stats(Ypred1[:T],Ypred0[:T])\n",
    "  train_stats.append(stat)\n",
    "  print('Train:', stat)\n",
    "\n",
    "  evaluator_test = Evaluator(y=Yte, t=Wte, y_cf=Y_cfte, mu0=mute[0,:], mu1=mute[1,:])\n",
    "  stat = evaluator_test.calc_stats(Ypred1[T:],Ypred0[T:])\n",
    "  test_stats.append(stat)\n",
    "  print('Test:', stat)\n",
    "  \n",
    "  sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1565707762810,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "j2-IwGrZcnM5",
    "outputId": "fa8eca59-7935-45ad-b105-cad7430a4bf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.01575284, 0.3012461 , 0.31006412]),\n",
       " array([0.03870804, 0.07096629, 0.06939494]))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_stats,axis=0), np.std(train_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1565707765985,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "gSDi9g76hfUe",
    "outputId": "6ef9cdde-331d-49ed-9255-2785508382c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.2295829 , 0.29969135, 0.30558967]),\n",
       " array([0.15176145, 0.06939312, 0.068086  ]))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_stats,axis=0), np.std(test_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LMCM - RT - NN2H.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
