{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keMKeHoVmnR1"
   },
   "source": [
    "# Train and evaluate the model on NNH6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xM-VeXKduSt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import random\n",
    "from time import sleep\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20369,
     "status": "ok",
     "timestamp": 1590855749448,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "vN8QLpgkAnHG",
    "outputId": "6345dfb9-27c9-4e64-9094-65e166112000"
   },
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "from evaluation import Evaluator\n",
    "from datasets import NN6H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1565642894962,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "8GT8Pb7DKUvY",
    "outputId": "38a16172-6d2f-4833-da99-14c2ca81b0de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.17303466796875"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0).total_memory/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68RcyZ5_F9xH"
   },
   "outputs": [],
   "source": [
    "loss_bce = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "def lossPY(alphay, weighty, y, z, w, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  \n",
    "  if cov == None:\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, Kw, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + w.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  \n",
    "  f = weighty + lz + lw + ls\n",
    "\n",
    "  return torch.sum((y - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def QZ(alphaq, weightq, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "  \n",
    "def lossQZ(alphaq, weightq, z, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "  \n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  f = weightq + ly + lx + lw + ls\n",
    "  \n",
    "  return torch.sum((z - f.reshape(-1,1))**2) - 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPX(alphax, weightx, x, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return torch.sum((x - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def lossPW(alphaw, weightw, w, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "    \n",
    "  lz = torch.sum(Kz*alphaw[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphaw[:,1],dim=1)\n",
    "  \n",
    "  f = weightw + lz + ls\n",
    "\n",
    "  return loss_bce(f.reshape(-1,1),w) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPS(weights, s):\n",
    "  return torch.sum((s - weights)**2)\n",
    "\n",
    "\n",
    "def lossPZ(alphaz, weightz, z):\n",
    "  Kz = maternz(z, z).evaluate()*lower_ones\n",
    "  alphaz_ = torch.cat((alphaz[:,0], torch.tensor([1.0, 1.0])))\n",
    "  f = weightz + torch.sum(Kz*alphaz_,dim=1)[:-1]\n",
    "  return torch.sum((z[0] - weightz)**2) + torch.sum((z[1:] - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def trainModel(x, y, w, s, cov=None, n_iter=20000):\n",
    "  loss_lst = []\n",
    "  prog = trange(n_iter, desc='', leave=True)\n",
    "  for t in prog:\n",
    "      mean_z = QZ(alphaq, weightq, y, x, w, s, cov)\n",
    "      z = mean_z + torch.randn(mean_z.shape)\n",
    "\n",
    "      loss = lossPY(alphay, weighty, y, z, w, s, cov) + lossPX(alphax, weightx, x, z, s, cov) +\\\n",
    "              lossPW(alphaw, weightw, w, z, s, cov) + lossPS(weights, s) +\\\n",
    "                lossPZ(alphaz, weightz, z) - lossQZ(alphaq, weightq, z, y, x, w, s, cov)\n",
    "\n",
    "      if t%50 == 0:\n",
    "        prog.set_postfix_str(\"Iter {}:, Loss: {}\".format(t,loss.item()))\n",
    "        prog.refresh()\n",
    "        \n",
    "      loss_lst.append(loss.item())\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer.step()\n",
    "  return np.asarray(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bne9WNZKR0a"
   },
   "outputs": [],
   "source": [
    "def predZ(alphaq, weightq, y, x, w, s, ynew, xnew, wnew, snew):\n",
    "  Ky = materny(ynew, y).evaluate()\n",
    "  Kx = maternx(xnew, x).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "\n",
    "\n",
    "def evalLogPX(alphax, weightx, x, z, s, xpre, zpre, spre):\n",
    "  Kz = maternz(zpre, z).evaluate()\n",
    "  Ks = materns(spre, s).evaluate()\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return (-0.5*np.log(2*np.pi) - 0.5*(Xpre - f.reshape(-1,1))**2).detach().numpy().flatten()\n",
    "\n",
    "def sampleY(z, w, s, znew, wnew, snew, alphay, weighty, weights_mixture, T, n):\n",
    "  Y_samples = []\n",
    "  \n",
    "  Kz = maternz(znew, z).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  f = weighty + lz + lw + ls\n",
    "  for i in range(n):\n",
    "    noise = torch.from_numpy(np.random.normal(0,1,T)).float()\n",
    "\n",
    "    Y = f + noise\n",
    "    Y_samples.append(Y.detach().numpy())\n",
    "  return np.asarray(Y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1776718,
     "status": "ok",
     "timestamp": 1590857565721,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "jBK2tVSYp5o4",
    "outputId": "b5303ccc-f4b4-4120-aeaf-949e1cfb4a4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:56<00:00, 113.50it/s, Iter 19950:, Loss: 5992.83251953125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0587999056848756, 0.1823316670227051, 0.18745555954551035)\n",
      "Test: (1.3066916514791855, 0.19189368255615058, 0.19652102990343343)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:56<00:00, 113.38it/s, Iter 19950:, Loss: 9922.2470703125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8696838029789734, 0.10425863115883693, 0.11625597568008196)\n",
      "Test: (0.5734634348047454, 0.10222683914184483, 0.1116357236360923)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:56<00:00, 113.48it/s, Iter 19950:, Loss: 11191.6923828125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.151884114814651, 0.21192465789794745, 0.21739472877064908)\n",
      "Test: (1.0501331278048278, 0.21083746917724433, 0.21484059069597353)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:56<00:00, 113.05it/s, Iter 19950:, Loss: 7467.16015625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9564222749088469, 0.5136689089965838, 0.5154258090066108)\n",
      "Test: (0.6179454356054885, 0.5113915347290074, 0.513529969938156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:57<00:00, 112.46it/s, Iter 19950:, Loss: 9068.7138671875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.1542243741347713, 0.1009203337860125, 0.11017525811126898)\n",
      "Test: (1.2240790174576168, 0.09803046218872158, 0.10563695751161684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:57<00:00, 112.88it/s, Iter 19950:, Loss: 8206.6015625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0129690418334443, 0.09983407028198243, 0.10912020519950548)\n",
      "Test: (1.2614269352030745, 0.10676871307372693, 0.1159710758140374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:57<00:00, 112.89it/s, Iter 19950:, Loss: 6631.01806640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.2990844947457612, 0.7398310757446289, 0.7411637128290431)\n",
      "Test: (0.9816370656505978, 0.7416187382507307, 0.7429945017184215)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:55<00:00, 113.90it/s, Iter 19950:, Loss: 10605.2919921875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0347511266105083, 0.18378840454101386, 0.18972639873904582)\n",
      "Test: (1.4932997706001334, 0.1783748722839329, 0.1817394003019568)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:56<00:00, 113.13it/s, Iter 19950:, Loss: 8057.81201171875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9278925671668757, 0.3700829886627215, 0.37268082515134315)\n",
      "Test: (0.9830194069851704, 0.3626350306701678, 0.36552224075270223)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:55<00:00, 113.72it/s, Iter 19950:, Loss: 8060.18994140625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.281922270470204, 0.3828484416483686, 0.3938759077325166)\n",
      "Test: (1.5176142657744616, 0.36767588623046876, 0.3715577918522637)\n"
     ]
    }
   ],
   "source": [
    "learn_hyper = False\n",
    "\n",
    "dataset = NN6H(replications=10)\n",
    "\n",
    "train_stats = []\n",
    "test_stats = []\n",
    "loss_lst = []\n",
    "for i, (train, valid, test, contfeats, binfeats) in enumerate(dataset.get_train_valid_test()):\n",
    "  W, Y, Y_cf, mu, X, S = train[0][1].reshape(-1), train[0][2].reshape(-1), train[1][0].reshape(-1),\\\n",
    "                          np.concatenate((train[1][1],train[1][2]),axis=1).T, train[0][0][:,0], train[0][0][:,1]\n",
    "  T = len(Y)\n",
    "  x = torch.from_numpy(X.reshape(T,-1)).float() \n",
    "  y = torch.from_numpy(Y.reshape(-1,1)).float()\n",
    "  w = torch.from_numpy(W.reshape(-1,1)).float()\n",
    "  s = torch.from_numpy(S.reshape(T,-1)).float()\n",
    "  \n",
    "  Wte, Yte, Y_cfte, mute, Xte, Ste = test[0][1].reshape(-1), test[0][2].reshape(-1), test[1][0].reshape(-1), \\\n",
    "                                      np.concatenate((test[1][1],test[1][2]), axis=1).T, test[0][0][:,0], test[0][0][:,1]\n",
    "  Tte = len(Yte)\n",
    "  xte = torch.from_numpy(Xte.reshape(Tte,-1)).float() \n",
    "  yte = torch.from_numpy(Yte.reshape(-1,1)).float()\n",
    "  wte = torch.from_numpy(Wte.reshape(-1,1)).float()\n",
    "  ste = torch.from_numpy(Ste.reshape(Tte,-1)).float()\n",
    "  \n",
    "  lower_ones = torch.ones(len(y), len(y))\n",
    "  lower_ones[np.triu_indices(len(y))] = 0\n",
    "  \n",
    "  # Compute kernel matrices\n",
    "  maternx = gpytorch.kernels.RBFKernel()\n",
    "  maternx.initialize(lengthscale=10.0)\n",
    "  materns = gpytorch.kernels.RBFKernel()\n",
    "  materns.initialize(lengthscale=10.0)\n",
    "  materny = gpytorch.kernels.RBFKernel()\n",
    "  materny.initialize(lengthscale=10.0)\n",
    "  maternz = gpytorch.kernels.RBFKernel()\n",
    "  maternz.initialize(lengthscale=10.0)\n",
    "  maternw = gpytorch.kernels.RBFKernel()\n",
    "  maternw.initialize(lengthscale=10.0)\n",
    "  \n",
    "  Ky = materny(y, y).evaluate()\n",
    "  Kx = maternx(x, x).evaluate()\n",
    "  Kw = maternw(w, w).evaluate()\n",
    "  Ks = materns(s, s).evaluate()\n",
    "  if learn_hyper == False:\n",
    "    cov = (Ky, Kw, Kx, Ks)\n",
    "  else:\n",
    "    cov = None\n",
    "  \n",
    "  # Declare parameters\n",
    "  alphay = torch.rand(len(y), 4, requires_grad=True)\n",
    "  weighty = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaq = torch.rand(len(y), 5, requires_grad=True)\n",
    "  weightq = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphax = torch.rand(len(x), 2, requires_grad=True)\n",
    "  weightx = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaw = torch.rand(len(w), 2, requires_grad=True)\n",
    "  weightw = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  weights = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaz = torch.rand(len(y)-2, 1, requires_grad=True)\n",
    "  weightz = torch.rand(1, requires_grad=True)  \n",
    "  \n",
    "  # Train\n",
    "  params = [alphay, alphaq, alphax, alphaw, alphaz, weighty, weightq, weightx, weightw, weightz, weights]\n",
    "  if learn_hyper == True:\n",
    "    params = params + list(maternx.parameters()) + list(materns.parameters()) + list(maternw.parameters()) \\\n",
    "                    + list(materny.parameters()) + list(maternz.parameters())\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "  loss_train = trainModel(x, y, w, s, cov=cov, n_iter=20000)\n",
    "  loss_lst.append(loss_train)\n",
    "\n",
    "  # Sample Ypred\n",
    "  z_samples = predZ(alphaq, weightq, y, x, w, s,\n",
    "                   torch.cat((y,yte),dim=0), torch.cat((x,xte),dim=0), torch.cat((w,wte),dim=0), torch.cat((s,ste),dim=0)).transpose(0,1)\n",
    "  weights_mixture = 1.0\n",
    "\n",
    "  Y_samples1 = sampleY(z_samples[0,:T].reshape(-1,1), torch.ones((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.ones((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Y_samples2 = sampleY(z_samples[0,:T].reshape(-1,1), torch.zeros((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.zeros((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Ypred1 = np.mean(Y_samples1,axis=0)\n",
    "  Ypred0 = np.mean(Y_samples2,axis=0)\n",
    "  \n",
    "  # Evaluate\n",
    "  evaluator_train = Evaluator(y=Y, t=W, y_cf=Y_cf, mu0=mu[0,:], mu1=mu[1,:])\n",
    "  stat = evaluator_train.calc_stats(Ypred1[:T],Ypred0[:T])\n",
    "  train_stats.append(stat)\n",
    "  print('Train:', stat)\n",
    "\n",
    "  evaluator_test = Evaluator(y=Yte, t=Wte, y_cf=Y_cfte, mu0=mute[0,:], mu1=mute[1,:])\n",
    "  stat = evaluator_test.calc_stats(Ypred1[T:],Ypred0[T:])\n",
    "  test_stats.append(stat)\n",
    "  print('Test:', stat)\n",
    "  \n",
    "  sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1590857567873,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "j2-IwGrZcnM5",
    "outputId": "04b6fd48-9337-4761-b479-d307a0cd2102"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0747634 , 0.28894892, 0.29532744]),\n",
       " array([0.10290512, 0.06651968, 0.06580125]))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_stats,axis=0), np.std(test_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1590857569404,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "gSDi9g76hfUe",
    "outputId": "ab10c537-5640-42b7-c0f4-39b19c26db22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.10093101, 0.28714532, 0.29199493]),\n",
       " array([0.10290512, 0.06651968, 0.06580125]))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_stats,axis=0), np.std(test_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LMCM - RT - NN6H - RBF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
