{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keMKeHoVmnR1"
   },
   "source": [
    "# Train and evaluate the model on NN6HIID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xM-VeXKduSt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import random\n",
    "from time import sleep\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5797,
     "status": "ok",
     "timestamp": 1565734668148,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "vN8QLpgkAnHG",
    "outputId": "982e143e-ff5c-4acd-c2fc-ad754b11dde6"
   },
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "from evaluation import Evaluator\n",
    "from datasets import NN6HIID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5788,
     "status": "ok",
     "timestamp": 1565734668150,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "8GT8Pb7DKUvY",
    "outputId": "b1443ede-8b8a-49a8-ae30-82669a81e9a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.17303466796875"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0).total_memory/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68RcyZ5_F9xH"
   },
   "outputs": [],
   "source": [
    "loss_bce = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "def lossPY(alphay, weighty, y, z, w, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  \n",
    "  if cov == None:\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, Kw, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + w.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  \n",
    "  f = weighty + lz + lw + ls\n",
    "\n",
    "  return torch.sum((y - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def QZ(alphaq, weightq, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "  \n",
    "def lossQZ(alphaq, weightq, z, y, x, w, s, cov):\n",
    "  if cov == None:\n",
    "    Ky = materny(y, y).evaluate()\n",
    "    Kx = maternx(x, x).evaluate()\n",
    "    Kw = maternw(w, w).evaluate()\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    Ky, Kw, Kx, Ks = cov\n",
    "  \n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-w.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + w.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  f = weightq + ly + lx + lw + ls\n",
    "  \n",
    "  return torch.sum((z - f.reshape(-1,1))**2) - 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPX(alphax, weightx, x, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return torch.sum((x - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def lossPW(alphaw, weightw, w, z, s, cov):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  if cov == None:\n",
    "    Ks = materns(s, s).evaluate()\n",
    "  else:\n",
    "    _, _, _, Ks = cov\n",
    "    \n",
    "  lz = torch.sum(Kz*alphaw[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphaw[:,1],dim=1)\n",
    "  \n",
    "  f = weightw + lz + ls\n",
    "\n",
    "  return loss_bce(f.reshape(-1,1),w) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "def lossPS(weights, s):\n",
    "  return torch.sum((s - weights)**2)\n",
    "\n",
    "\n",
    "def lossPZ(alphaz, weightz, z):\n",
    "  Kz = maternz(z, z).evaluate()\n",
    "  Kz[np.triu_indices(len(z))] = 0\n",
    "  alphaz_ = torch.cat((alphaz[:,0], torch.tensor([1.0, 1.0])))\n",
    "  f = weightz + torch.sum(Kz*alphaz_,dim=1)[:-1]\n",
    "  return torch.sum((z[0] - weightz)**2) + torch.sum((z[1:] - f.reshape(-1,1))**2) + 1e-3*torch.sum(f**2)\n",
    "\n",
    "\n",
    "def trainModel(x, y, w, s, cov=None, n_iter=20000):\n",
    "  loss_lst = []\n",
    "  prog = trange(n_iter, desc='', leave=True)\n",
    "  for t in prog:\n",
    "      mean_z = QZ(alphaq, weightq, y, x, w, s, cov)\n",
    "      z = mean_z + torch.randn(mean_z.shape)\n",
    "\n",
    "      loss = lossPY(alphay, weighty, y, z, w, s, cov) + lossPX(alphax, weightx, x, z, s, cov) +\\\n",
    "              lossPW(alphaw, weightw, w, z, s, cov) + lossPS(weights, s) +\\\n",
    "                lossPZ(alphaz, weightz, z) - lossQZ(alphaq, weightq, z, y, x, w, s, cov)\n",
    "\n",
    "      if t%50 == 0:\n",
    "        prog.set_postfix_str(\"Iter {}:, Loss: {}\".format(t,loss.item()))\n",
    "        prog.refresh()\n",
    "        \n",
    "      loss_lst.append(loss.item())\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer.step()\n",
    "  return np.asarray(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bne9WNZKR0a"
   },
   "outputs": [],
   "source": [
    "def predZ(alphaq, weightq, y, x, w, s, ynew, xnew, wnew, snew):\n",
    "  Ky = materny(ynew, y).evaluate()\n",
    "  Kx = maternx(xnew, x).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  ly = torch.sum(Ky*alphaq[:,0],dim=1)\n",
    "  lx = torch.sum(Kx*alphaq[:,1],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphaq[:,2],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphaq[:,3],dim=1)\n",
    "  ls = torch.sum(Ks*alphaq[:,4],dim=1)\n",
    "  \n",
    "  z = weightq + ly + lx + lw + ls\n",
    "  return z.reshape(-1,1)\n",
    "\n",
    "\n",
    "def evalLogPX(alphax, weightx, x, z, s, xpre, zpre, spre):\n",
    "  Kz = maternz(zpre, z).evaluate()\n",
    "  Ks = materns(spre, s).evaluate()\n",
    "  \n",
    "  lz = torch.sum(Kz*alphax[:,0],dim=1)\n",
    "  ls = torch.sum(Ks*alphax[:,1],dim=1)\n",
    "  \n",
    "  f = weightx + lz + ls\n",
    "  \n",
    "  return (-0.5*np.log(2*np.pi) - 0.5*(Xpre - f.reshape(-1,1))**2).detach().numpy().flatten()\n",
    "\n",
    "def sampleY(z, w, s, znew, wnew, snew, alphay, weighty, weights_mixture, T, n):\n",
    "  Y_samples = []\n",
    "  \n",
    "  Kz = maternz(znew, z).evaluate()\n",
    "  Kw = maternw(wnew, w).evaluate()\n",
    "  Ks = materns(snew, s).evaluate()\n",
    "\n",
    "  lz = torch.sum(Kz*alphay[:,0],dim=1)\n",
    "  lw = (1-wnew.reshape(-1))*torch.sum(Kw*alphay[:,1],dim=1) + wnew.reshape(-1)*torch.sum(Kw*alphay[:,2],dim=1)\n",
    "  ls = torch.sum(Ks*alphay[:,3],dim=1)\n",
    "  f = weighty + lz + lw + ls\n",
    "  for i in range(n):\n",
    "    noise = torch.from_numpy(np.random.normal(0,1,T)).float()\n",
    "\n",
    "    Y = f + noise\n",
    "    Y_samples.append(Y.detach().numpy())\n",
    "  return np.asarray(Y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3249608,
     "status": "ok",
     "timestamp": 1565737911992,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "jBK2tVSYp5o4",
    "outputId": "5c1d0c18-04b1-4692-cec6-7275a94fd421"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:25<00:00, 61.50it/s, Iter 19950:, Loss: 1405.01171875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2.333076654415837, 0.16165876800298706, 0.6159433625352297)\n",
      "Test: (2.4907430034844666, 0.06307313504835221, 0.26226735756384734)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:26<00:00, 61.20it/s, Iter 19950:, Loss: 1037.4764404296875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.0510448213654289, 0.5324210428988216, 0.6990859353302801)\n",
      "Test: (1.1017983659130703, 0.657324683910061, 0.8857055203793798)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:23<00:00, 61.91it/s, Iter 19950:, Loss: 1123.697509765625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8209173104459693, 0.01967205680726014, 0.4259366283506738)\n",
      "Test: (0.87501457238768, 0.05297394037538261, 0.30142692965546414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:25<00:00, 61.41it/s, Iter 19950:, Loss: 1128.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9494310614295505, 0.23468357117812744, 0.6727165022914562)\n",
      "Test: (0.8754719591156763, 0.05269638747613392, 0.11421766350020175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:24<00:00, 61.62it/s, Iter 19950:, Loss: 1145.5191650390625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.4483258509112604, 1.1541938595581511, 1.3308447632089788)\n",
      "Test: (1.4515142707756385, 1.0430126655030687, 1.2811496740825914)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:22<00:00, 61.93it/s, Iter 19950:, Loss: 1093.498291015625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.136584370029858, 0.7367082780401977, 0.9649142428980364)\n",
      "Test: (0.9104606048291694, 0.7166582390824567, 0.8995590734724425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:25<00:00, 61.51it/s, Iter 19950:, Loss: 1069.9444580078125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1.1263170242151135, 0.7692866148965081, 0.9217062314988991)\n",
      "Test: (0.7685538565942818, 0.6624944662919017, 0.6915104917598784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:19<00:00, 62.60it/s, Iter 19950:, Loss: 1112.33203125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.9366978083907311, 0.1483045870852564, 0.524512868179805)\n",
      "Test: (1.4232390681441214, 0.027221784667968763, 0.04419020826219277)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:21<00:00, 62.25it/s, Iter 19950:, Loss: 1072.5673828125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0.8710053360397035, 0.22773112578819488, 0.5465070961005984)\n",
      "Test: (0.9796836199172883, 0.2462596389211802, 0.41046761582457575)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [05:22<00:00, 61.96it/s, Iter 19950:, Loss: 1442.0521240234375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2.285131723134564, 0.6545666114593436, 0.7388310019981029)\n",
      "Test: (3.220936822351201, 0.5952482939265087, 0.6402942760651091)\n"
     ]
    }
   ],
   "source": [
    "learn_hyper = False\n",
    "\n",
    "dataset = NN6HIID(replications=10)\n",
    "\n",
    "train_stats = []\n",
    "test_stats = []\n",
    "loss_lst = []\n",
    "for i, (train, valid, test, contfeats, binfeats) in enumerate(dataset.get_train_valid_test()):\n",
    "  W, Y, Y_cf, mu, X, S = train[0][1].reshape(-1), train[0][2].reshape(-1), train[1][0].reshape(-1),\\\n",
    "                          np.concatenate((train[1][1],train[1][2]),axis=1).T, train[0][0][:,0], train[0][0][:,1]\n",
    "  T = len(Y)\n",
    "  x = torch.from_numpy(X.reshape(T,-1)).float() \n",
    "  y = torch.from_numpy(Y.reshape(-1,1)).float()\n",
    "  w = torch.from_numpy(W.reshape(-1,1)).float()\n",
    "  s = torch.from_numpy(S.reshape(T,-1)).float()\n",
    "  \n",
    "  Wte, Yte, Y_cfte, mute, Xte, Ste = test[0][1].reshape(-1), test[0][2].reshape(-1), test[1][0].reshape(-1), \\\n",
    "                                      np.concatenate((test[1][1],test[1][2]), axis=1).T, test[0][0][:,0], test[0][0][:,1]\n",
    "  Tte = len(Yte)\n",
    "  xte = torch.from_numpy(Xte.reshape(Tte,-1)).float() \n",
    "  yte = torch.from_numpy(Yte.reshape(-1,1)).float()\n",
    "  wte = torch.from_numpy(Wte.reshape(-1,1)).float()\n",
    "  ste = torch.from_numpy(Ste.reshape(Tte,-1)).float()\n",
    "  \n",
    "  # Compute kernel matrices\n",
    "  maternx = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternx.initialize(lengthscale=10.0)\n",
    "  materns = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  materns.initialize(lengthscale=10.0)\n",
    "  materny = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  materny.initialize(lengthscale=10.0)\n",
    "  maternz = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternz.initialize(lengthscale=10.0)\n",
    "  maternw = gpytorch.kernels.MaternKernel(nu=3/2)\n",
    "  maternw.initialize(lengthscale=10.0)\n",
    "  \n",
    "  Ky = materny(y, y).evaluate()\n",
    "  Kx = maternx(x, x).evaluate()\n",
    "  Kw = maternw(w, w).evaluate()\n",
    "  Ks = materns(s, s).evaluate()\n",
    "  if learn_hyper == False:\n",
    "    cov = (Ky, Kw, Kx, Ks)\n",
    "  else:\n",
    "    cov = None\n",
    "  \n",
    "  # Declare parameters\n",
    "  alphay = torch.rand(len(y), 4, requires_grad=True)\n",
    "  weighty = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaq = torch.rand(len(y), 5, requires_grad=True)\n",
    "  weightq = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphax = torch.rand(len(x), 2, requires_grad=True)\n",
    "  weightx = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaw = torch.rand(len(w), 2, requires_grad=True)\n",
    "  weightw = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  weights = torch.rand(1, requires_grad=True)\n",
    "\n",
    "  alphaz = torch.rand(len(y)-2, 1, requires_grad=True)\n",
    "  weightz = torch.rand(1, requires_grad=True)  \n",
    "  \n",
    "  # Train\n",
    "  params = [alphay, alphaq, alphax, alphaw, alphaz, weighty, weightq, weightx, weightw, weightz, weights]\n",
    "  if learn_hyper == True:\n",
    "    params = params + list(maternx.parameters()) + list(materns.parameters()) + list(maternw.parameters()) \\\n",
    "                    + list(materny.parameters()) + list(maternz.parameters())\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "  loss_train = trainModel(x, y, w, s, cov=cov, n_iter=20000)\n",
    "  loss_lst.append(loss_train)\n",
    "\n",
    "  # Sample Ypred\n",
    "  z_samples = predZ(alphaq, weightq, y, x, w, s,\n",
    "                   torch.cat((y,yte),dim=0), torch.cat((x,xte),dim=0), torch.cat((w,wte),dim=0), torch.cat((s,ste),dim=0)).transpose(0,1)\n",
    "  weights_mixture = 1.0\n",
    "\n",
    "  Y_samples1 = sampleY(z_samples[0,:T].reshape(-1,1), torch.ones((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.ones((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Y_samples2 = sampleY(z_samples[0,:T].reshape(-1,1), torch.zeros((T,1)), s.reshape(-1,1),\n",
    "                       z_samples[0,:].reshape(-1,1), torch.zeros((T+Tte,1)), torch.cat((s,ste),dim=0).reshape(-1,1),\n",
    "                       alphay, weighty, weights_mixture, T=T+Tte, n=1000)\n",
    "  Ypred1 = np.mean(Y_samples1,axis=0)\n",
    "  Ypred0 = np.mean(Y_samples2,axis=0)\n",
    "  \n",
    "  # Evaluate\n",
    "  evaluator_train = Evaluator(y=Y, t=W, y_cf=Y_cf, mu0=mu[0,:], mu1=mu[1,:])\n",
    "  stat = evaluator_train.calc_stats(Ypred1[:T],Ypred0[:T])\n",
    "  train_stats.append(stat)\n",
    "  print('Train:', stat)\n",
    "\n",
    "  evaluator_test = Evaluator(y=Yte, t=Wte, y_cf=Y_cfte, mu0=mute[0,:], mu1=mute[1,:])\n",
    "  stat = evaluator_test.calc_stats(Ypred1[T:],Ypred0[T:])\n",
    "  test_stats.append(stat)\n",
    "  print('Test:', stat)\n",
    "  \n",
    "  sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3249607,
     "status": "ok",
     "timestamp": 1565737911999,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "j2-IwGrZcnM5",
    "outputId": "31e831ca-03d8-4f2b-a6f4-7bb41277623e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.2958532 , 0.46392265, 0.74409986]),\n",
       " array([0.17785304, 0.11459321, 0.08410545]))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_stats,axis=0), np.std(train_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3249601,
     "status": "ok",
     "timestamp": 1565737912000,
     "user": {
      "displayName": "Thanh Vinh Vo",
      "photoUrl": "",
      "userId": "07597300543628396596"
     },
     "user_tz": -480
    },
    "id": "gSDi9g76hfUe",
    "outputId": "f2f83363-3552-43a4-cc6e-58e411ffef3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.40974161, 0.41169632, 0.55307888]),\n",
       " array([0.25739029, 0.1156036 , 0.12504891]))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_stats,axis=0), np.std(test_stats,axis=0,ddof=1)/np.sqrt(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LMCM - NN6HIID.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
